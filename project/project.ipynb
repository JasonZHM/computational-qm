{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flow Model for Lattice Field Theory\n",
    "\n",
    "Author: Haimeng Zhao\n",
    "\n",
    "Email: haimengzhao@icloud.com\n",
    "\n",
    "This notebook contains the code and a detailed note for utilizing flow-based models to sample from complicated probability distributions, especially those encountered in many-body systems.\n",
    "\n",
    "The method implemented here is based on several papers ([arXiv:1904.12072](https://inspirehep.net/literature/1731778), [arXiv:2002.02428](https://inspirehep.net/literature/1779199), and [arXiv:2003.06413](https://inspirehep.net/literature/1785309)) and a tutorial [arXiv:2101.08176](https://arxiv.org/abs/2101.08176). \n",
    "\n",
    "We first import some useful packages and check whether GPUs are available (if not, CPUs will be used instead)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TORCH DEVICE: cuda\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "# Use CPU or GPU\n",
    "if torch.cuda.is_available():\n",
    "    torch_device = 'cuda'\n",
    "    float_dtype = np.float32 # single\n",
    "    torch.set_default_tensor_type(torch.cuda.FloatTensor)\n",
    "else:\n",
    "    torch_device = 'cpu'\n",
    "    float_dtype = np.float64 # double\n",
    "    torch.set_default_tensor_type(torch.DoubleTensor)\n",
    "print(f\"TORCH DEVICE: {torch_device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we borrow some useful functions from 2101.08176.\n",
    "\n",
    "- `grab` is used to move tensors to cpu. \n",
    "\n",
    "- `init_live_plot, moving_average, update_plots` is used to make live-updating plots for monitoring training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Ref: 2101.08176\n",
    "'''\n",
    "\n",
    "def grab(var):\n",
    "    return var.detach().cpu().numpy()\n",
    "\n",
    "from IPython.display import display\n",
    "\n",
    "def init_live_plot(dpi=125, figsize=(8,4)):\n",
    "    fig, ax_ess = plt.subplots(1,1, dpi=dpi, figsize=figsize)\n",
    "    plt.xlim(0, N_era*N_epoch)\n",
    "    plt.ylim(0, 1)\n",
    "    \n",
    "    ess_line = plt.plot([0],[0], alpha=0.5) # dummy\n",
    "    plt.grid(False)\n",
    "    plt.ylabel('ESS')\n",
    "    \n",
    "    ax_loss = ax_ess.twinx()\n",
    "    loss_line = plt.plot([0],[0], alpha=0.5, c='orange') # dummy\n",
    "    plt.grid(False)\n",
    "    plt.ylabel('Loss')\n",
    "    \n",
    "    plt.xlabel('Epoch')\n",
    "\n",
    "    display_id = display(fig, display_id=True)\n",
    "\n",
    "    return dict(\n",
    "        fig=fig, ax_ess=ax_ess, ax_loss=ax_loss,\n",
    "        ess_line=ess_line, loss_line=loss_line,\n",
    "        display_id=display_id\n",
    "    )\n",
    "\n",
    "def moving_average(x, window=10):\n",
    "    if len(x) < window:\n",
    "        return np.mean(x, keepdims=True)\n",
    "    else:\n",
    "        return np.convolve(x, np.ones(window), 'valid') / window\n",
    "\n",
    "def update_plots(history, fig, ax_ess, ax_loss, ess_line, loss_line, display_id):\n",
    "    Y = np.array(history['ess'])\n",
    "    Y = moving_average(Y, window=15)\n",
    "    ess_line[0].set_ydata(Y)\n",
    "    ess_line[0].set_xdata(np.arange(len(Y)))\n",
    "    Y = history['loss']\n",
    "    Y = moving_average(Y, window=15)\n",
    "    loss_line[0].set_ydata(np.array(Y))\n",
    "    loss_line[0].set_xdata(np.arange(len(Y)))\n",
    "    ax_loss.relim()\n",
    "    ax_loss.autoscale_view()\n",
    "    fig.canvas.draw()\n",
    "    display_id.update(fig) # need to force colab to update plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "The essential idea behind this method is to use a neural network to learn the transformation from a simple distribution (the prior), which can be easily sampled, to the complicated distribution we target at (see the figure below from 1904.12072).\n",
    "\n",
    "![Fig. 1 of 1904.12072](./assets/normalizing_flow.png)\n",
    "\n",
    "For example, we can choose the prior to be a simple normal distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NormalPrior:\n",
    "    def __init__(self, mean, var):\n",
    "        self.mean = torch.flatten(mean)\n",
    "        self.var = torch.flatten(var)\n",
    "        self.dist = torch.distributions.normal.Normal(self.mean, self.var)\n",
    "        self.shape = mean.shape\n",
    "\n",
    "    def log_prob(self, x):\n",
    "        logp = self.dist.log_prob(x.reshape(x.shape[0], -1))\n",
    "        return torch.sum(logp, dim=1)\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        x = self.dist.sample((batch_size,))\n",
    "        return x.reshape(batch_size, *self.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that here for the purpose of lattice field theory, we assume the target density $p(x)$ to be $e^{-S}/Z$, where $S$ is the action of the field theory and $Z$ the normalization constant.\n",
    "\n",
    "When the neural network successfully learned the desired transformation, we can then sample from the prior and apply the neural network to map our samples to the desired distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_flow_to_prior(prior, layers, batch_size):\n",
    "    # sample from prior\n",
    "    x = prior.sample(batch_size)\n",
    "    logq = prior.log_prob(x)\n",
    "\n",
    "    # flow through the model\n",
    "    for l in layers:\n",
    "        x, logJ = layer.forward(x)\n",
    "        logq = logq - logJ\n",
    "    \n",
    "    return x, logq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the neural network represents a gradual \"flow\" of distribution from the prior to the target, it is called a flow model. To further stress that each slice of the flow is a distribution itself which satisfies the normalizing condition $\\int p(x) dx = 1$, the model is often called a normalizing flow.\n",
    "\n",
    "However, the trained neural network is only an approximation, thus the samples drawn directly through the flow is biased. To produce unbiased samples and thus measure observables, we still need resample precedures such as Markov chain Monte Carlo (MCMC). (If you only need an approximation, direct sampling through the flow will be enough).\n",
    "\n",
    "But this time MCMC will require significantly less burn-in time and is more robust to model parameters thanks to the flow. Furthermore, sampling with the flow is also free from the fermion sign problem (though it requires the flow to have a property called \"equivariant\", which happens to be met by the well-known transformer model from the field of natural language processing). Thus the resulting MCMC-flow hybrid sampler is much better than a simple MCMC.\n",
    "\n",
    "To quantify the quality of flow model samples, we can use the effective sample size (ESS) (which serves a similar role as autocorrelation time in MCMC)\n",
    "$$\n",
    "ESS = \\frac{ \\left(\\frac{1}{N} \\sum_i p(x_i)/q(x_i) \\right)^2 }{ \\frac{1}{N} \\sum_i \\left( p(x_i)/q(x_i) \\right)^2 } \\in [0, 1].\n",
    "$$\n",
    "Here a larger ESS indicates better sampling, and $ESS=1$ represents a perfect sampling from the desired distribution.\n",
    "\n",
    "For later use, we borrow the MCMC code from 2101.08176."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Ref: 2101.08176\n",
    "'''\n",
    "\n",
    "def serial_sample_generator(model, action, batch_size, N_samples):\n",
    "    '''\n",
    "    Generate samples from prior and flow through the model, \n",
    "    yield logq and logp alongside.\n",
    "\n",
    "    Here for lattice field theory purpose, we assume p = e^{-S}/Z, \n",
    "    where S is the action of the field theory.\n",
    "    '''\n",
    "    layers, prior = model['layers'], model['prior']\n",
    "    layers.eval()\n",
    "    x, logq, logp = None, None, None\n",
    "    for i in range(N_samples):\n",
    "        batch_i = i % batch_size\n",
    "        if batch_i == 0:\n",
    "            # we're out of samples to propose, generate a new batch\n",
    "            x, logq = apply_flow_to_prior(prior, layers, batch_size=batch_size)\n",
    "            logp = -action(x)\n",
    "        yield x[batch_i], logq[batch_i], logp[batch_i]\n",
    "    \n",
    "def make_mcmc_ensemble(model, action, batch_size, N_samples):\n",
    "    history = {\n",
    "        'x' : [],\n",
    "        'logq' : [],\n",
    "        'logp' : [],\n",
    "        'accepted' : []\n",
    "    }\n",
    "\n",
    "    # build Markov chain\n",
    "    sample_gen = serial_sample_generator(model, action, batch_size, N_samples)\n",
    "    for new_x, new_logq, new_logp in sample_gen:\n",
    "        if len(history['logp']) == 0:\n",
    "            # always accept first proposal, Markov chain must start somewhere\n",
    "            accepted = True\n",
    "        else: \n",
    "            # Metropolis acceptance condition\n",
    "            last_logp = history['logp'][-1]\n",
    "            last_logq = history['logq'][-1]\n",
    "            p_accept = torch.exp((new_logp - new_logq) - (last_logp - last_logq))\n",
    "            p_accept = min(1, p_accept)\n",
    "            draw = torch.rand(1) # ~ [0,1]\n",
    "            if draw < p_accept:\n",
    "                accepted = True\n",
    "            else:\n",
    "                accepted = False\n",
    "                new_x = history['x'][-1]\n",
    "                new_logp = last_logp\n",
    "                new_logq = last_logq\n",
    "        # Update Markov chain\n",
    "        history['logp'].append(new_logp)\n",
    "        history['logq'].append(new_logq)\n",
    "        history['x'].append(new_x)\n",
    "        history['accepted'].append(accepted)\n",
    "    return history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalizing Flow\n",
    "\n",
    "Now we dive into the detail of normalizing flow.\n",
    "\n",
    "Translating the above intuition into rigorous math, we aim to find a transformation $f(z)$ which maps a random variable $z$ with a simple prior density $r(z)$ to the ouput variable $x = f(z)$ with density $q(x)$. By the change-of-variable formula we have\n",
    "\n",
    "$$\n",
    "q(x) = r(z)|J|^{-1} = r(z)\\left |\\det \\frac{\\partial f_i(z)}{\\partial z_j}\\right |^{-1},\n",
    "$$\n",
    "\n",
    "where $J = \\det \\frac{\\partial f_i(z)}{\\partial z_j}$ is the Jacobian. \n",
    "\n",
    "That's all it is! A change of variable. Now we only need to train a neural network to find the optimal $f$ which minimizes the distance between the output density $q(x)$ and the target density $p(x)$:\n",
    "$$\n",
    "f = \\argmin_f d(q, p).\n",
    "$$\n",
    "\n",
    "A common choice use to measure the distance between two distributions is the Kullback-Leibler (KL) divergence\n",
    "$$\n",
    "D_{KL}(q||p) = \\int dx \\ q(x)[\\log q(x) - \\log p(x)],\n",
    "$$\n",
    "which can be estimated by\n",
    "$$\n",
    "\\hat{D}_{KL}(q||p) = \\frac{1}{N}\\sum_i^N[\\log q(x_i) - \\log p(x_i)], \\quad x_i \\sim q.\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kl_divergence(logp, logq):\n",
    "    return torch.mean(logq - logp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can see the advantage of flow models compared with traditional method. We only need to sample from the \"model distribution\" $q(x)$, which can be generated easily from the prior, while traditional methods such as HMC require sampling from $p(x)$.\n",
    "\n",
    "To make it short, our training procedure consists of\n",
    "1. Drawing samples from the prior and flow through the model,\n",
    "2. Estimate the KL divergence,\n",
    "3. Use optimization methods such as SGD or Adam to minimize the KL divergence.\n",
    "\n",
    "During training, we monitor the KL divergence (loss function) and ESS to keep track of the training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, action, optimizer, batch_size, metrics):\n",
    "    layers, prior = model['layers'], model['prior']\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    x, logq = apply_flow_to_prior(prior, layers, batch_size)\n",
    "    logp = -action(x)\n",
    "    loss = kl_divergence(logp, logq)\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    metrics['loss'].append(grab(loss))\n",
    "    metrics['logp'].append(grab(logp))\n",
    "    metrics['logq'].append(grab(logq))\n",
    "    metrics['ess'].append(grab(compute_ess(logp, logq)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we are left with now is how to design a flow $f$ that is expressive enough while keeping its Jacobian tractable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
